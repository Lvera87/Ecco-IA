import sys
import os

# Ensure backend root is in path
sys.path.append(os.getcwd())

print("ğŸ” Verificando entorno e integraciÃ³n de IA...\n")

try:
    import onnxruntime
    print(f"âœ… LibrerÃ­a ONNX Runtime detectada (v{onnxruntime.__version__})")
except ImportError:
    print("âŒ ONNX Runtime NO estÃ¡ instalado.")

print("------------------------------------------------")

try:
    # Simulamos el boot de la aplicaciÃ³n
    from app.services.ia_service import ia
    
    print("â³ Ejecutando ia.load_artifacts()...")
    ia.load_artifacts()
    
    print("\nğŸ“Š REPORTE FINAL DE AUDITORÃA:")
    print(f"â¤ Estado del Servicio:   {'âœ… LISTO' if ia.is_loaded else 'âŒ ERROR'}")
    print(f"â¤ Motor de Inferencia:   {'ğŸš€ DEEP LEARNING (ONNX)' if ia.using_dl else 'ğŸ¢ LEGACY (Scikit-learn)'}")
    
    if ia.using_dl:
        print("\nğŸ‰ Â¡Ã‰XITO! El modelo de Deep Learning fue detectado y cargado.")
    else:
        print("\nâš ï¸ AVISO: El sistema estÃ¡ operativo pero usando el modelo ANTIGUO.")
        print("   RazÃ³n: No se encontrÃ³ el archivo 'cerebro_deeplearning.onnx'")
        print(f"   Ruta esperada: {os.path.abspath('app/ML/Algoritmos/cerebro_deeplearning.onnx')}")

except Exception as e:
    print(f"\nâŒ ERROR CRÃTICO DURANTE LA CARGA: {e}")
